{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "4_kis_hf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dV6qgdT7Q4u",
        "outputId": "7d2f66be-f68a-458a-97fc-22e08c257ebd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install openimages # install the openimages library"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting openimages\n",
            "  Downloading https://files.pythonhosted.org/packages/49/ba/587944c183999aa9a0416d6979739b78adfe021eee74aa9db78f0beaea06/openimages-0.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from openimages) (4.41.1)\n",
            "Collecting cvdata\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/e5/5361375b284ac1da759cf78329f8484cb33c039c4c91e38862ca4cba2ae6/cvdata-0.0.7-py2.py3-none-any.whl (49kB)\n",
            "\r\u001b[K     |██████▋                         | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 20kB 29.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 30kB 32.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 40kB 35.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from openimages) (4.2.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from openimages) (1.1.4)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/f7/a0f1e13222e10d426afbc50fc7de3c65acafa6ff4cc790e71e649d4cd9ad/boto3-1.16.15-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 27.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from openimages) (2.23.0)\n",
            "Collecting tensorflow-cpu>=2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/1a/0dff6c8421f84b2f104adf48c8ad8b9ae5a693417868abacfab9f133c122/tensorflow_cpu-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (137.3MB)\n",
            "\u001b[K     |████████████████████████████████| 137.3MB 88kB/s \n",
            "\u001b[?25hCollecting ImageHash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/5d/cc81830be3c4705a46cdbca74439b67f1017881383ba0127c41c4cecb7b3/ImageHash-4.1.0.tar.gz (291kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 30.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from cvdata->openimages) (0.5.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from cvdata->openimages) (7.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from cvdata->openimages) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas->openimages) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->openimages) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->openimages) (2.8.1)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 12.0MB/s \n",
            "\u001b[?25hCollecting botocore<1.20.0,>=1.19.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/1d/bed1bb297abadc387d8328d88ac7612daa2d9f716bd83ec096ceb4a9f8bb/botocore-1.19.15-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 54.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->openimages) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->openimages) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->openimages) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->openimages) (2.10)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (1.33.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (1.1.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (1.6.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (0.3.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (2.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (0.10.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (1.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from ImageHash->cvdata->openimages) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.6/dist-packages (from ImageHash->cvdata->openimages) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow-cpu>=2.1->cvdata->openimages) (50.3.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (1.7.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (3.1.0)\n",
            "Building wheels for collected packages: ImageHash\n",
            "  Building wheel for ImageHash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ImageHash: filename=ImageHash-4.1.0-py2.py3-none-any.whl size=291991 sha256=4a13f5a6a7c36787e115f01748bf3cfac0e21614b176b45f3a635643160145c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/1c/dc/6831446f09feb8cc199ec73a0f2f0703253f6ae013a22f4be9\n",
            "Successfully built ImageHash\n",
            "\u001b[31mERROR: botocore 1.19.15 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-cpu, ImageHash, cvdata, jmespath, botocore, s3transfer, boto3, openimages\n",
            "Successfully installed ImageHash-4.1.0 boto3-1.16.15 botocore-1.19.15 cvdata-0.0.7 jmespath-0.10.0 openimages-0.0.1 s3transfer-0.3.3 tensorflow-cpu-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_K2iwxA73qI"
      },
      "source": [
        "# import the libraries for the project\n",
        "import os\n",
        "from openimages.download import download_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3,preprocess_input,decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "import seaborn\n",
        "import numpy as np\n",
        "import shutil"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwYeIfrF8FBQ",
        "outputId": "f1a1dc13-e45a-4ffa-bbb5-6225d8598245",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "image_cnt = 600 # number of images from each category\n",
        "download_dataset('/tmp/images', ['Bird', 'Boot','Sunglasses'], annotation_format='pascal', limit=image_cnt) # download the images into the /tmp/images forder"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-11  20:27:32 INFO NumExpr defaulting to 2 threads.\n",
            "2020-11-11  20:27:34 INFO Downloading 600 train images for class 'bird'\n",
            "100%|██████████| 600/600 [00:05<00:00, 101.02it/s]\n",
            "2020-11-11  20:27:41 INFO Creating 600 train annotations (pascal) for class 'bird'\n",
            "100%|██████████| 600/600 [00:00<00:00, 1858.09it/s]\n",
            "2020-11-11  20:27:42 INFO Downloading 600 train images for class 'boot'\n",
            "100%|██████████| 600/600 [00:06<00:00, 86.16it/s]\n",
            "2020-11-11  20:27:49 INFO Creating 600 train annotations (pascal) for class 'boot'\n",
            "100%|██████████| 600/600 [00:00<00:00, 2461.88it/s]\n",
            "2020-11-11  20:27:50 INFO Downloading 600 train images for class 'sunglasses'\n",
            "100%|██████████| 600/600 [00:06<00:00, 92.66it/s]\n",
            "2020-11-11  20:27:56 INFO Creating 600 train annotations (pascal) for class 'sunglasses'\n",
            "100%|██████████| 600/600 [00:00<00:00, 2692.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bird': {'annotations_dir': '/tmp/images/bird/pascal',\n",
              "  'images_dir': '/tmp/images/bird/images'},\n",
              " 'boot': {'annotations_dir': '/tmp/images/boot/pascal',\n",
              "  'images_dir': '/tmp/images/boot/images'},\n",
              " 'sunglasses': {'annotations_dir': '/tmp/images/sunglasses/pascal',\n",
              "  'images_dir': '/tmp/images/sunglasses/images'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN5Bm_y5AIVy"
      },
      "source": [
        "# directory names of the downloaded images\n",
        "base_dir = '/tmp/images'\n",
        "bird_dir = os.path.join(base_dir, 'bird/images')\n",
        "boot_dir = os.path.join(base_dir, 'boot/images')\n",
        "sunglasses_dir = os.path.join(base_dir, 'sunglasses/images')\n",
        "\n",
        "# lis the file names of the downloaded images and concatenate them to the directory they are in\n",
        "bird_fnames = os.listdir(bird_dir)\n",
        "boot_fnames = os.listdir(boot_dir)\n",
        "sunglasses_fnames = os.listdir(sunglasses_dir)\n",
        "for i in range(image_cnt):\n",
        "  bird_fnames[i] = os.path.join(bird_dir, bird_fnames[i])\n",
        "  boot_fnames[i] = os.path.join(boot_dir, boot_fnames[i])\n",
        "  sunglasses_fnames[i] = os.path.join(sunglasses_dir, sunglasses_fnames[i])\n",
        "\n",
        "# split the image file name array to train, validation and test arrays\n",
        "bird_train, bird_2 = train_test_split(bird_fnames, test_size=1/3, shuffle=True)\n",
        "bird_valid, bird_test = train_test_split(bird_2, test_size=1/2, shuffle=True)\n",
        "boot_train, boot_2 = train_test_split(boot_fnames, test_size=1/3, shuffle=True)\n",
        "boot_valid, boot_test = train_test_split(boot_2, test_size=1/2, shuffle=True)\n",
        "sunglasses_train, sunglasses_2 = train_test_split(sunglasses_fnames, test_size=1/3, shuffle=True)\n",
        "sunglasses_valid, sunglasses_test = train_test_split(sunglasses_2, test_size=1/2, shuffle=True)\n",
        "\n",
        "# directories for the train, validation and test data\n",
        "train_dir = '/tmp/train'\n",
        "valid_dir = '/tmp/valid'\n",
        "test_dir = '/tmp/test'\n",
        "\n",
        "# create the folders for the train, validation and test data and copy the images to the appropriate folder\n",
        "try:\n",
        "  os.mkdir(train_dir)\n",
        "  os.mkdir(os.path.join(train_dir, 'bird'))\n",
        "  os.mkdir(os.path.join(train_dir, 'boot'))\n",
        "  os.mkdir(os.path.join(train_dir, 'sunglasses'))\n",
        "except:\n",
        "  print(\"Train folder already exists.\")\n",
        "for i in bird_train:\n",
        "  shutil.copy(i, os.path.join(train_dir, 'bird'))\n",
        "for i in boot_train:\n",
        "  shutil.copy(i, os.path.join(train_dir, 'boot'))\n",
        "for i in sunglasses_train:\n",
        "  shutil.copy(i, os.path.join(train_dir, 'sunglasses'))\n",
        "\n",
        "try:\n",
        "  os.mkdir(valid_dir)\n",
        "  os.mkdir(os.path.join(valid_dir, 'bird'))\n",
        "  os.mkdir(os.path.join(valid_dir, 'boot'))\n",
        "  os.mkdir(os.path.join(valid_dir, 'sunglasses'))\n",
        "except:\n",
        "  print(\"Validation folder already exists.\")\n",
        "for i in bird_valid:\n",
        "  shutil.copy(i, os.path.join(valid_dir, 'bird'))\n",
        "for i in boot_valid:\n",
        "  shutil.copy(i, os.path.join(valid_dir, 'boot'))\n",
        "for i in sunglasses_valid:\n",
        "  shutil.copy(i, os.path.join(valid_dir, 'sunglasses'))\n",
        "\n",
        "try:\n",
        "  os.mkdir(test_dir)\n",
        "  os.mkdir(os.path.join(test_dir, 'bird'))\n",
        "  os.mkdir(os.path.join(test_dir, 'boot'))\n",
        "  os.mkdir(os.path.join(test_dir, 'sunglasses'))\n",
        "except:\n",
        "  print(\"Test folder already exists.\")\n",
        "for i in bird_test:\n",
        "  shutil.copy(i, os.path.join(test_dir, 'bird'))\n",
        "for i in boot_test:\n",
        "  shutil.copy(i, os.path.join(test_dir, 'boot'))\n",
        "for i in sunglasses_test:\n",
        "  shutil.copy(i, os.path.join(test_dir, 'sunglasses'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkfq67BZFc5l"
      },
      "source": [
        "# input image size of the downloaded model\n",
        "img_height=299\n",
        "img_width=299\n",
        "\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False) # download the inception_v3 model without the top layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x) # to flatten the 2D convolution\n",
        "x = Dense(2048, activation='relu')(x) # new layer of 2048 neurons with relu activation\n",
        "predictions = Dense(3, activation='softmax')(x) # the output layer consists of 3 neurons for each category\n",
        "model = Model(inputs=base_model.input, outputs=predictions) # create our model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwKN83j1ggcR"
      },
      "source": [
        "# make all layers in the downloaded model untrainable\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy') # compile our model with the appropriate parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OQlj93YKJb2",
        "outputId": "6add3ca9-01e7-48b5-e80f-ef5f3105b846",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# function to enrich the downloaded data to train our model\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "# data generators to train our model\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(img_height, img_width), batch_size=20, class_mode='categorical', shuffle=True)\n",
        "valid_generator = valid_datagen.flow_from_directory(valid_dir, target_size=(img_height, img_width), batch_size=20, class_mode='categorical', shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1200 images belonging to 3 classes.\n",
            "Found 300 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgXT7eVtQk72",
        "outputId": "602d3988-f141-4fe4-afd7-45b3322e732f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "checkpoint1 = ModelCheckpoint(filepath='/tmp/model1.h5', save_best_only=True, verbose=0) # save the trained model into a file, since training can be time consuming\n",
        "model.fit_generator(train_generator, steps_per_epoch=60, validation_data=valid_generator, validation_steps=10, epochs=3, callbacks=[checkpoint1]) # train our model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "60/60 [==============================] - 245s 4s/step - loss: 1.0613 - accuracy: 0.7883 - val_loss: 0.1805 - val_accuracy: 0.9350\n",
            "Epoch 2/3\n",
            "60/60 [==============================] - 243s 4s/step - loss: 0.1401 - accuracy: 0.9567 - val_loss: 0.1915 - val_accuracy: 0.9400\n",
            "Epoch 3/3\n",
            "60/60 [==============================] - 243s 4s/step - loss: 0.1800 - accuracy: 0.9367 - val_loss: 0.1656 - val_accuracy: 0.9400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6e35106048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKB0pP_8wgt5"
      },
      "source": [
        "test_fnames = bird_test + boot_test + sunglasses_test # test file names (concatenated to the directory they are in) into one array\n",
        "test_input = []\n",
        "# load and preprocess each test image and put them into one array which will be the input of the model during testing\n",
        "for i in test_fnames:\n",
        "  img = image.load_img(i, target_size=(299, 299))\n",
        "  x = image.img_to_array(img)\n",
        "  x = preprocess_input(x)\n",
        "  test_input.append(x)\n",
        "test_input = np.asarray(test_input) # the created test input array as numpy array\n",
        "# create the test output array\n",
        "test_output = np.full(shape=(100), fill_value=0)\n",
        "test_output = np.concatenate((test_output, np.full(shape=(100), fill_value=1)), axis=0)\n",
        "test_output = np.concatenate((test_output, np.full(shape=(100), fill_value=2)), axis=0)\n",
        "test_input, test_output = shuffle(test_input, test_output) # shuffle the testing input and output array the same way"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1HCfgL9DiXy",
        "outputId": "b97bfa6f-db53-4fe9-e845-748c9c11b452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "model = load_model('/tmp/model1.h5') # load our trained model from the file\n",
        "predict = model.predict(test_input) # predict the output for all test images\n",
        "conf_matrix = confusion_matrix(test_output, np.argmax(predict, axis=1)) # create a confusion matrix from the model output and the correct solution of the test database\n",
        "seaborn.heatmap(conf_matrix, annot=True) # show the results on a heatmap"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6e32ff0518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnV3oaKIyIvD"
      },
      "source": [
        "# make the layers from the 172. layer trainable\n",
        "for layer in model.layers[172:]:\n",
        "       layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), metrics=['accuracy'], loss='categorical_crossentropy') # compile our model with the appropriate parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_UDzmyfyY_a",
        "outputId": "2974716e-a9cb-4aa0-dfe8-ca5ba3ddd065",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "checkpoint2 = ModelCheckpoint(filepath='/tmp/model2.h5', save_best_only=True, verbose=0) # save the trained model into a file, since training can be time consuming\n",
        "model.fit_generator(train_generator,steps_per_epoch=60, validation_data=valid_generator, validation_steps=10, epochs=3, callbacks=[checkpoint2]) # train our model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "60/60 [==============================] - 416s 7s/step - loss: 0.2527 - accuracy: 0.9125 - val_loss: 0.1466 - val_accuracy: 0.9550\n",
            "Epoch 2/3\n",
            "60/60 [==============================] - 416s 7s/step - loss: 0.1782 - accuracy: 0.9458 - val_loss: 0.1483 - val_accuracy: 0.9400\n",
            "Epoch 3/3\n",
            "60/60 [==============================] - 416s 7s/step - loss: 0.1314 - accuracy: 0.9567 - val_loss: 0.1384 - val_accuracy: 0.9450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6e32dd1d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmIOj8TmJtYd",
        "outputId": "205d1186-1523-4b52-c148-a4da01e590b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "model = load_model('/tmp/model2.h5') # load our trained model from the file\n",
        "predict = model.predict(test_input) # predict the output for all test images\n",
        "conf_matrix = confusion_matrix(test_output, np.argmax(predict, axis=1)) # create a confusion matrix from the model output and the correct solution of the test database\n",
        "seaborn.heatmap(conf_matrix, annot=True) # show the results on a heatmap"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6e19074898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}